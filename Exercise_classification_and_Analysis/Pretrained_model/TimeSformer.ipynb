{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GGE6niLXU0vS",
    "outputId": "01e68be0-f805-4063-8b55-52316448a090"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers datasets torch torchvision opencv-python kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jftNbQsvVjD4"
   },
   "source": [
    "# Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zg1yRCzNeA7m"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# input_path = \"/kaggle/input\"\n",
    "# for root, dirs, files in os.walk(input_path):\n",
    "#     for file in files:\n",
    "#         if file.endswith(\".zip\"):\n",
    "#             print(os.path.join(root, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fPDORiPLfSVQ",
    "outputId": "1bb2b850-8b46-41c7-8cb0-4ca40a5b45b1"
   },
   "outputs": [],
   "source": [
    "# !pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cj3VSm_VfTB8",
    "outputId": "c798019e-df6d-4fa7-e853-8e3347cd7bac"
   },
   "outputs": [],
   "source": [
    "\n",
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"hasyimabdillah/workoutfitness-video\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_300qZT1fYCb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, frames_per_video=8):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.frames_per_video = frames_per_video\n",
    "        self.video_paths = glob.glob(os.path.join(root_dir, '*/*.mp4'))\n",
    "        self.label_map = {label: idx for idx, label in enumerate(sorted(os.listdir(root_dir)))}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "\n",
    "    def read_video_frames(self, video_path):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        frame_idxs = torch.linspace(0, total_frames - 1, self.frames_per_video).long().tolist()\n",
    "        frames = []\n",
    "\n",
    "        for i in range(total_frames):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            if i in frame_idxs:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                if self.transform:\n",
    "                    frame = self.transform(frame)\n",
    "                frames.append(frame)\n",
    "\n",
    "        cap.release()\n",
    "        return torch.stack(frames)  # shape: (T, C, H, W)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.video_paths[idx]\n",
    "        label = os.path.basename(os.path.dirname(video_path))\n",
    "        video_tensor = self.read_video_frames(video_path)\n",
    "        return video_tensor, self.label_map[label]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MTbxpEDfr8u"
   },
   "source": [
    "# Define Transformer and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2SwPW4lxfjVx"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = VideoDataset(r\"F:\\quest_digiflex\\exp\\data\\archive\", transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xTc3KKyf65H"
   },
   "source": [
    "# Load TimeSfomer from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289,
     "referenced_widgets": [
      "57c07df903ba4ad3b6ffa7e4130406a8",
      "79f594f490fd479b90717cfbf5d0d5c3",
      "b6192186e7ee4927bda7789eb2bb4c10",
      "0258a7d497f840f09c50beebb929b991",
      "ead8aea3dda94bc7bf96f5025d30850f",
      "ec19fd1b8b6c4ef08037af48d2129dbf",
      "749bd61c8a994cba9c26cebfc176f976",
      "24b9f1f7e7bd4898a355eedc83b55f30",
      "43bb44e0846b4e57973cb90b75885e74",
      "b00972f4ff314f58bae95d24a052f3c3",
      "1a7eca0d2895457fbb9bddaf906af02a",
      "0ae7c7022b3a4846b968bed5bd3ad002",
      "e560b288566343bfb751b00c49df5245",
      "35d19eecca2343c8a3af41706f8f15ae",
      "03337622938e48aa8090a1d7b217094b",
      "ff7d006720c64044b24213c17fdaea0d",
      "a9180d1612a64b639089127534cdaf9d",
      "bff9f3a9198a45b5ba83f1296123a0d6",
      "13fa456b32ea4c2abde46707d3411759",
      "5b9056559af0492abb2aeca2ecf0b9ed",
      "2d2fe3ecdce547cdbd6f589267d3f60e",
      "cf37ac8ef8e748cf813e3c2bc1941342",
      "1c334228a6e04e6984b0e02e4671c0bd",
      "d46f57a4139642ba81dbaf164c79def5",
      "912e2a48a51a4737bcabf960a187e559",
      "3fef5db636504f748b9f05bd8c64b6b8",
      "31e14adcb3584941a764e8629929a20c",
      "31187a84c89d48a09ba0b71def1fb1d7",
      "0341a5867eb742849873a4b6dfc193ed",
      "87b51556dcd2484c9b722744e99156e8",
      "c55a0520f6db4374b1a84266f0bbd23c",
      "6c5baf33f1284414ad277433712e501f",
      "60961e2f069e401f9e4b0284e4e64c22"
     ]
    },
    "id": "4bMcDi7_fheZ",
    "outputId": "670205f0-5d8d-492b-a338-ca427e56405f"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForVideoClassification, AutoImageProcessor\n",
    "\n",
    "model = AutoModelForVideoClassification.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")\n",
    "processor = AutoImageProcessor.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")\n",
    "\n",
    "# Adjust number of classes if needed\n",
    "model.classifier = torch.nn.Linear(model.classifier.in_features, len(dataset.label_map))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "007KVOYUgHud"
   },
   "outputs": [],
   "source": [
    "# Fine-tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1iQTmqq2jy75"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = VideoDataset(r\"F:\\quest_digiflex\\exp\\test\\test\", transform=transform)\n",
    "dataloader_val = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VWVlv0_8lDOM",
    "outputId": "99186c16-154d-4b7d-87cf-a7c40d523c9c"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "val_loader = DataLoader(dataset_val, batch_size=2, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Jo1s01HkArz",
    "outputId": "8623399a-31ad-4c70-e421-c79dd4f3f937"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimesformerForVideoClassification(\n",
       "  (timesformer): TimesformerModel(\n",
       "    (embeddings): TimesformerEmbeddings(\n",
       "      (patch_embeddings): TimesformerPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "      (time_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): TimesformerEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x TimesformerLayer(\n",
       "          (drop_path): Identity()\n",
       "          (attention): TimeSformerAttention(\n",
       "            (attention): TimesformerSelfAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): TimesformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): TimesformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): TimesformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (temporal_attention): TimeSformerAttention(\n",
       "            (attention): TimesformerSelfAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): TimesformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=22, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForVideoClassification\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = AutoModelForVideoClassification.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")\n",
    "model.classifier = torch.nn.Linear(model.classifier.in_features, len(dataset.label_map))  # Adjust num classes\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "_pw4C3JKl0MR"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TimesformerConfig, TimesformerModel\n",
    "import torch.nn as nn\n",
    "\n",
    "class TimeSformerWithDropout(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(TimeSformerWithDropout, self).__init__()\n",
    "        self.backbone = TimesformerModel.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.classifier = nn.Linear(self.backbone.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, video):\n",
    "        outputs = self.backbone(video)\n",
    "        x = self.dropout(outputs.last_hidden_state[:, 0])  # CLS token\n",
    "        logits = self.classifier(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import random\n",
    "\n",
    "frame_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomApply([transforms.ColorJitter(brightness=0.2, contrast=0.2)], p=0.5),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.05, 0.05)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected classes: 22\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_root = r\"F:\\quest_digiflex\\exp\\data\\archive\"  # your dataset folder\n",
    "num_classes = len(next(os.walk(dataset_root))[1])\n",
    "print(\"Detected classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "\n",
    "# num_classes = 22  # <-- Add this line\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = TimeSformerWithDropout(num_classes=num_classes).to(device)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "# num_epochs = 10\n",
    "\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "\n",
    "#     for i, (videos, labels) in enumerate(train_loader):\n",
    "#         videos, labels = videos.to(device), labels.to(device)\n",
    "\n",
    "#         logits = model(videos)\n",
    "#         loss = criterion(logits, labels)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         running_loss += loss.item()\n",
    "#         preds = logits.argmax(dim=1)\n",
    "#         correct += (preds == labels).sum().item()\n",
    "#         total += labels.size(0)\n",
    "\n",
    "#     acc = correct / total\n",
    "#     print(f\"Epoch [{epoch+1}/{num_epochs}] | Loss: {running_loss:.4f} | Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dn2ZvRXel2ah",
    "outputId": "9becb936-f2f4-4b49-d7eb-2b59151a3b7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] | Loss: 401.3763 | Accuracy: 0.6661\n",
      "Epoch [2/5] | Loss: 47.1124 | Accuracy: 0.9831\n",
      "Epoch [3/5] | Loss: 12.4966 | Accuracy: 0.9966\n",
      "Epoch [4/5] | Loss: 5.0691 | Accuracy: 1.0000\n",
      "Epoch [5/5] | Loss: 3.2462 | Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# num_epochs = 5\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "\n",
    "#     for i, (videos, labels) in enumerate(train_loader):\n",
    "#         # videos: (B, T, C, H, W) → TimeSformer expects (B, T, C, H, W)\n",
    "#         videos, labels = videos.to(device), labels.to(device)\n",
    "\n",
    "#         outputs = model(videos)\n",
    "#         loss = criterion(outputs.logits, labels)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # Track metrics\n",
    "#         running_loss += loss.item()\n",
    "#         preds = outputs.logits.argmax(dim=1)\n",
    "#         correct += (preds == labels).sum().item()\n",
    "#         total += labels.size(0)\n",
    "\n",
    "#     acc = correct / total\n",
    "#     print(f\"Epoch [{epoch+1}/{num_epochs}] | Loss: {running_loss:.4f} | Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|▏                                                                     | 1/295 [00:49<4:04:49, 49.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 0/295 | Loss: 3.4782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|█▍                                                                    | 6/295 [03:50<2:58:41, 37.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 5/295 | Loss: 0.9098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|██▌                                                                  | 11/295 [06:40<2:37:16, 33.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 10/295 | Loss: 3.4086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|███▋                                                                 | 16/295 [09:28<2:34:14, 33.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 15/295 | Loss: 3.1575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|████▉                                                                | 21/295 [11:58<2:18:31, 30.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 20/295 | Loss: 2.1232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|██████                                                               | 26/295 [14:24<2:10:56, 29.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 25/295 | Loss: 3.6706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|███████▎                                                             | 31/295 [16:57<2:13:50, 30.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 30/295 | Loss: 2.6890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|████████▍                                                            | 36/295 [19:27<2:10:03, 30.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 35/295 | Loss: 3.5274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█████████▌                                                           | 41/295 [22:03<2:10:00, 30.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 40/295 | Loss: 2.7424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|██████████▊                                                          | 46/295 [24:28<2:00:15, 28.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 45/295 | Loss: 2.9789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|███████████▉                                                         | 51/295 [26:52<1:56:26, 28.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 50/295 | Loss: 2.8348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█████████████                                                        | 56/295 [29:19<1:58:17, 29.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 55/295 | Loss: 2.4002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██████████████▎                                                      | 61/295 [31:46<1:55:06, 29.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 60/295 | Loss: 3.7444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|███████████████▍                                                     | 66/295 [34:11<1:50:55, 29.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 65/295 | Loss: 2.2797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|████████████████▌                                                    | 71/295 [36:41<1:49:46, 29.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 70/295 | Loss: 1.1517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|█████████████████▊                                                   | 76/295 [39:06<1:46:28, 29.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 75/295 | Loss: 1.4134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██████████████████▉                                                  | 81/295 [41:36<1:47:52, 30.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 80/295 | Loss: 3.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|████████████████████                                                 | 86/295 [44:02<1:41:25, 29.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 85/295 | Loss: 2.0776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  31%|█████████████████████▎                                               | 91/295 [46:30<1:42:00, 30.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 90/295 | Loss: 1.7605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|██████████████████████▍                                              | 96/295 [48:57<1:37:02, 29.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 95/295 | Loss: 2.1420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  34%|███████████████████████▎                                            | 101/295 [51:23<1:33:55, 29.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 100/295 | Loss: 1.3911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|████████████████████████▍                                           | 106/295 [53:43<1:28:06, 27.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 105/295 | Loss: 2.7671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|█████████████████████████▌                                          | 111/295 [56:05<1:26:23, 28.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 110/295 | Loss: 1.9781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|██████████████████████████▋                                         | 116/295 [58:25<1:23:18, 27.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 115/295 | Loss: 0.4686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|███████████████████████████                                       | 121/295 [1:00:53<1:22:38, 28.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 120/295 | Loss: 0.7157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████████████████████████████▏                                     | 126/295 [1:03:17<1:20:21, 28.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 125/295 | Loss: 2.3695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|█████████████████████████████▎                                    | 131/295 [1:05:36<1:16:09, 27.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 130/295 | Loss: 0.8351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|██████████████████████████████▍                                   | 136/295 [1:08:04<1:16:31, 28.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 135/295 | Loss: 3.1007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|███████████████████████████████▌                                  | 141/295 [1:11:39<1:37:30, 37.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 140/295 | Loss: 0.8041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|████████████████████████████████▋                                 | 146/295 [1:14:05<1:16:26, 30.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 145/295 | Loss: 4.2095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  51%|█████████████████████████████████▊                                | 151/295 [1:16:51<1:19:25, 33.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 150/295 | Loss: 2.4263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  53%|██████████████████████████████████▉                               | 156/295 [1:19:29<1:17:57, 33.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 155/295 | Loss: 0.4460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|████████████████████████████████████                              | 161/295 [1:22:09<1:10:17, 31.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 160/295 | Loss: 0.9168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|█████████████████████████████████████▏                            | 166/295 [1:24:36<1:02:16, 28.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 165/295 | Loss: 1.0821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|██████████████████████████████████████▎                           | 171/295 [1:27:06<1:01:28, 29.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 170/295 | Loss: 2.1603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|████████████████████████████████████████▌                           | 176/295 [1:29:30<57:01, 28.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 175/295 | Loss: 2.2998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|█████████████████████████████████████████▋                          | 181/295 [1:31:53<53:43, 28.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 180/295 | Loss: 0.4889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  63%|██████████████████████████████████████████▊                         | 186/295 [1:34:15<51:57, 28.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 185/295 | Loss: 0.0840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████████████████████████████████████████▋                       | 191/295 [1:37:52<1:21:53, 47.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 190/295 | Loss: 2.7998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|███████████████████████████████████████████▊                      | 196/295 [1:41:38<1:09:28, 42.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 195/295 | Loss: 0.4628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|██████████████████████████████████████████████▎                     | 201/295 [1:44:12<50:51, 32.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 200/295 | Loss: 1.2121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████████████████████████████████████████████▍                    | 206/295 [1:46:49<47:49, 32.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 205/295 | Loss: 0.9717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|████████████████████████████████████████████████▋                   | 211/295 [1:50:16<55:04, 39.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 210/295 | Loss: 1.4338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  73%|█████████████████████████████████████████████████▊                  | 216/295 [1:53:41<54:25, 41.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 215/295 | Loss: 0.7375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|██████████████████████████████████████████████████▉                 | 221/295 [1:56:24<43:54, 35.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 220/295 | Loss: 1.3854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  77%|████████████████████████████████████████████████████                | 226/295 [1:58:54<35:04, 30.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 225/295 | Loss: 0.7007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|█████████████████████████████████████████████████████▏              | 231/295 [2:01:36<35:17, 33.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 230/295 | Loss: 0.1968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|██████████████████████████████████████████████████████▍             | 236/295 [2:04:18<31:24, 31.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 235/295 | Loss: 0.1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  82%|███████████████████████████████████████████████████████▌            | 241/295 [2:06:51<27:37, 30.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 240/295 | Loss: 0.5785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|████████████████████████████████████████████████████████▋           | 246/295 [2:09:35<26:10, 32.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 245/295 | Loss: 0.4458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|█████████████████████████████████████████████████████████▊          | 251/295 [2:12:21<24:11, 32.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 250/295 | Loss: 0.3143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  87%|███████████████████████████████████████████████████████████         | 256/295 [2:15:49<27:14, 41.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 255/295 | Loss: 1.3905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████████████████████████████████████████████████████████▏       | 261/295 [2:18:50<19:39, 34.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 260/295 | Loss: 0.1050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|█████████████████████████████████████████████████████████████▎      | 266/295 [2:21:25<15:39, 32.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 265/295 | Loss: 0.8388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|██████████████████████████████████████████████████████████████▍     | 271/295 [2:24:24<13:52, 34.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 270/295 | Loss: 3.2541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|███████████████████████████████████████████████████████████████▌    | 276/295 [2:27:08<10:19, 32.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 275/295 | Loss: 2.1219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|████████████████████████████████████████████████████████████████▊   | 281/295 [2:29:33<06:53, 29.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 280/295 | Loss: 2.1047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|█████████████████████████████████████████████████████████████████▉  | 286/295 [2:32:06<04:32, 30.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 285/295 | Loss: 0.1195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|███████████████████████████████████████████████████████████████████ | 291/295 [2:34:27<01:55, 28.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 290/295 | Loss: 0.0154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 295/295 [2:36:35<00:00, 31.85s/it]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 31/31 [07:30<00:00, 14.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [1/20] | Train Loss: 1.7182, Train Acc: 0.5153 | Val Loss: 1.8169, Val Acc: 0.4590\n",
      "🔖 Best model updated.\n",
      "\n",
      "🔁 Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|▏                                                                     | 1/295 [00:43<3:32:05, 43.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 0/295 | Loss: 0.0357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|█▍                                                                    | 6/295 [03:38<2:47:28, 34.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 5/295 | Loss: 0.0484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|██▌                                                                  | 11/295 [06:20<2:36:01, 32.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 10/295 | Loss: 0.1438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|███▋                                                                 | 16/295 [08:52<2:23:21, 30.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 15/295 | Loss: 0.6520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|████▉                                                                | 21/295 [11:23<2:17:27, 30.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 20/295 | Loss: 0.2106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|██████                                                               | 26/295 [13:46<2:09:24, 28.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 25/295 | Loss: 0.0136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|███████▎                                                             | 31/295 [16:18<2:11:30, 29.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 30/295 | Loss: 0.2453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|████████▍                                                            | 36/295 [18:51<2:13:44, 30.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 35/295 | Loss: 0.3518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█████████▌                                                           | 41/295 [21:47<2:21:01, 33.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 40/295 | Loss: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|██████████▊                                                          | 46/295 [25:32<2:54:52, 42.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 45/295 | Loss: 0.1114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|███████████▉                                                         | 51/295 [28:38<2:31:01, 37.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 50/295 | Loss: 0.0616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█████████████                                                        | 56/295 [31:24<2:21:41, 35.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 55/295 | Loss: 0.1719\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from tqdm import tqdm\n",
    "# import copy\n",
    "\n",
    "# # Constants\n",
    "# num_classes = 22\n",
    "# num_epochs = 20\n",
    "# patience = 3  # for early stopping\n",
    "# best_val_loss = float('inf')\n",
    "# early_stop_counter = 0\n",
    "\n",
    "# # Device setup\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Initialize model\n",
    "# model = TimeSformerWithDropout(num_classes=num_classes).to(device)\n",
    "\n",
    "# # Loss and optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# # To track best model\n",
    "# best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "# # Training loop\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(f\"\\n🔁 Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "#     # === Train ===\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "\n",
    "#     train_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Training\")\n",
    "#     for i, (videos, labels) in train_bar:\n",
    "#         videos, labels = videos.to(device), labels.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         logits = model(videos)\n",
    "#         loss = criterion(logits, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         running_loss += loss.item()\n",
    "#         preds = logits.argmax(dim=1)\n",
    "#         correct += (preds == labels).sum().item()\n",
    "#         total += labels.size(0)\n",
    "\n",
    "#         if i % 5 == 0:\n",
    "#             print(f\"📦 Train Batch {i}/{len(train_loader)} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "#     train_acc = correct / total\n",
    "#     train_loss = running_loss / len(train_loader)\n",
    "\n",
    "#     # === Validation ===\n",
    "#     model.eval()\n",
    "#     val_loss = 0.0\n",
    "#     val_correct = 0\n",
    "#     val_total = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         val_bar = tqdm(enumerate(val_loader), total=len(val_loader), desc=\"Validating\")\n",
    "#         for i, (videos, labels) in val_bar:\n",
    "#             videos, labels = videos.to(device), labels.to(device)\n",
    "#             logits = model(videos)\n",
    "#             loss = criterion(logits, labels)\n",
    "\n",
    "#             val_loss += loss.item()\n",
    "#             preds = logits.argmax(dim=1)\n",
    "#             val_correct += (preds == labels).sum().item()\n",
    "#             val_total += labels.size(0)\n",
    "\n",
    "#     val_acc = val_correct / val_total\n",
    "#     val_loss /= len(val_loader)\n",
    "\n",
    "#     # === Logging ===\n",
    "#     print(f\"✅ Epoch [{epoch+1}/{num_epochs}] | Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "#     # === Early Stopping ===\n",
    "#     if val_loss < best_val_loss:\n",
    "#         best_val_loss = val_loss\n",
    "#         best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#         early_stop_counter = 0\n",
    "#         print(\"🔖 Best model updated.\")\n",
    "#     else:\n",
    "#         early_stop_counter += 1\n",
    "#         print(f\"⚠️ No improvement in validation loss for {early_stop_counter} epoch(s).\")\n",
    "\n",
    "#     if early_stop_counter >= patience:\n",
    "#         print(\"⛔ Early stopping triggered.\")\n",
    "#         break\n",
    "\n",
    "# # Load best weights\n",
    "# model.load_state_dict(best_model_wts)\n",
    "\n",
    "# # Save best model\n",
    "# # torch.save(model.state_dict(), \"best_timesformer_model.pth\")\n",
    "# print(\"✅ Best model saved to 'best_timesformer_model.pth'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|▏                                                                     | 1/295 [00:37<3:03:32, 37.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 0/295 | Loss: 4.2632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|█▍                                                                    | 6/295 [03:35<2:47:03, 34.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 5/295 | Loss: 2.5579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|██▌                                                                  | 11/295 [08:36<5:43:13, 72.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 10/295 | Loss: 1.4865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|███▋                                                                 | 16/295 [13:57<4:36:37, 59.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 15/295 | Loss: 3.9088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|████▉                                                                | 21/295 [17:15<3:19:29, 43.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 20/295 | Loss: 4.2034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|██████                                                               | 26/295 [20:30<2:59:10, 39.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 25/295 | Loss: 0.8704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|███████▎                                                             | 31/295 [23:56<3:02:02, 41.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 30/295 | Loss: 1.8286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|████████▍                                                            | 36/295 [29:19<4:37:05, 64.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 35/295 | Loss: 3.4861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█████████▌                                                           | 41/295 [33:54<4:00:44, 56.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 40/295 | Loss: 3.3178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|██████████▊                                                          | 46/295 [38:24<3:39:26, 52.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 45/295 | Loss: 3.1683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|███████████▉                                                         | 51/295 [42:15<2:57:14, 43.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 50/295 | Loss: 1.4829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█████████████                                                        | 56/295 [45:56<2:47:16, 41.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 55/295 | Loss: 2.4675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██████████████▎                                                      | 61/295 [49:53<2:45:17, 42.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 60/295 | Loss: 2.4823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|███████████████▍                                                     | 66/295 [52:53<2:18:55, 36.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 65/295 | Loss: 2.2051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|████████████████▌                                                    | 71/295 [55:29<1:58:37, 31.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 70/295 | Loss: 1.1571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|█████████████████▊                                                   | 76/295 [57:58<1:51:03, 30.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 75/295 | Loss: 1.5133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██████████████████▍                                                | 81/295 [1:01:12<2:07:21, 35.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 80/295 | Loss: 2.8965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|███████████████████▌                                               | 86/295 [1:04:41<2:27:36, 42.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 85/295 | Loss: 3.5624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  31%|████████████████████▋                                              | 91/295 [1:08:28<2:39:04, 46.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 90/295 | Loss: 0.2192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|█████████████████████▊                                             | 96/295 [1:13:09<2:49:35, 51.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 95/295 | Loss: 1.1803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  34%|██████████████████████▌                                           | 101/295 [1:16:51<2:22:46, 44.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 100/295 | Loss: 1.3380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|███████████████████████▋                                          | 106/295 [1:19:50<2:01:07, 38.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 105/295 | Loss: 2.4729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|████████████████████████▊                                         | 111/295 [1:23:10<2:02:58, 40.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 110/295 | Loss: 1.3592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|█████████████████████████▉                                        | 116/295 [1:26:14<1:46:05, 35.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 115/295 | Loss: 0.6847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|███████████████████████████                                       | 121/295 [1:29:16<1:44:34, 36.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 120/295 | Loss: 0.5360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████████████████████████████▏                                     | 126/295 [1:32:59<2:04:07, 44.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 125/295 | Loss: 2.6629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|█████████████████████████████▎                                    | 131/295 [1:36:29<1:58:14, 43.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 130/295 | Loss: 2.4654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|██████████████████████████████▍                                   | 136/295 [1:39:57<1:46:44, 40.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 135/295 | Loss: 1.1438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|███████████████████████████████▌                                  | 141/295 [1:42:58<1:35:10, 37.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 140/295 | Loss: 0.7514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|████████████████████████████████▋                                 | 146/295 [1:46:27<1:42:50, 41.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 145/295 | Loss: 0.4047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  51%|█████████████████████████████████▊                                | 151/295 [1:49:39<1:31:06, 37.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 150/295 | Loss: 0.7486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  53%|██████████████████████████████████▉                               | 156/295 [1:52:44<1:27:05, 37.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 155/295 | Loss: 0.0652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|████████████████████████████████████                              | 161/295 [1:55:55<1:23:31, 37.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 160/295 | Loss: 0.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|█████████████████████████████████████▏                            | 166/295 [1:58:49<1:15:53, 35.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 165/295 | Loss: 1.3965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|██████████████████████████████████████▎                           | 171/295 [2:01:43<1:13:16, 35.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 170/295 | Loss: 1.8714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|███████████████████████████████████████▍                          | 176/295 [2:05:10<1:22:28, 41.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 175/295 | Loss: 1.3287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|████████████████████████████████████████▍                         | 181/295 [2:08:27<1:13:42, 38.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 180/295 | Loss: 0.2916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  63%|█████████████████████████████████████████▌                        | 186/295 [2:11:10<1:00:08, 33.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 185/295 | Loss: 1.7944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████████████████████████████████████████▋                       | 191/295 [2:14:06<1:00:10, 34.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 190/295 | Loss: 0.2642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|█████████████████████████████████████████████▏                      | 196/295 [2:16:42<53:14, 32.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 195/295 | Loss: 0.2225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|████████████████████████████████████████████▉                     | 201/295 [2:19:59<1:02:43, 40.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 200/295 | Loss: 0.0862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|██████████████████████████████████████████████                    | 206/295 [2:24:00<1:05:50, 44.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 205/295 | Loss: 0.0210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|███████████████████████████████████████████████▏                  | 211/295 [2:28:06<1:09:00, 49.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 210/295 | Loss: 2.2708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  73%|████████████████████████████████████████████████▎                 | 216/295 [2:33:08<1:18:38, 59.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Train Batch 215/295 | Loss: 5.2342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  73%|█████████████████████████████████████████████████▊                  | 216/295 [2:36:06<57:05, 43.36s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [7, 3, 224, 224] at entry 0 and [8, 3, 224, 224] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     46\u001b[0m train_bar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_loader), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (videos, labels) \u001b[38;5;129;01min\u001b[39;00m train_bar:\n\u001b[0;32m     48\u001b[0m     videos, labels \u001b[38;5;241m=\u001b[39m videos\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     50\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:212\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 212\u001b[0m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[0;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:272\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    270\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    271\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [7, 3, 224, 224] at entry 0 and [8, 3, 224, 224] at entry 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "\n",
    "# Constants\n",
    "num_classes = 22\n",
    "num_epochs = 20\n",
    "patience = 3\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model\n",
    "model = TimeSformerWithDropout(num_classes=num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# TensorBoard setup\n",
    "writer = SummaryWriter(log_dir=\"runs/timesformer_experiment\")\n",
    "\n",
    "# Best model tracking\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "# Class names (optional, if available)\n",
    "# class_names = [str(i) for i in range(num_classes)]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n🔁 Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    # === Train ===\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    train_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=\"Training\")\n",
    "    for i, (videos, labels) in train_bar:\n",
    "        videos, labels = videos.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(videos)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient Clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        if i % 5 == 0:\n",
    "            print(f\"📦 Train Batch {i}/{len(train_loader)} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_acc = correct / total\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # TensorBoard: log training metrics\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "\n",
    "    # === Validation ===\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(enumerate(val_loader), total=len(val_loader), desc=\"Validating\")\n",
    "        for i, (videos, labels) in val_bar:\n",
    "            videos, labels = videos.to(device), labels.to(device)\n",
    "            logits = model(videos)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds = logits.argmax(dim=1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    # TensorBoard: log validation metrics\n",
    "    writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/val', val_acc, epoch)\n",
    "\n",
    "    # === Logging ===\n",
    "    print(f\"✅ Epoch [{epoch+1}/{num_epochs}] | Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # === Confusion Matrix & Per-Class Accuracy ===\n",
    "    if epoch == num_epochs - 1 or val_loss < best_val_loss:\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        print(\"\\n📊 Confusion Matrix:\")\n",
    "        print(cm)\n",
    "\n",
    "        report = classification_report(all_labels, all_preds, digits=4)\n",
    "        print(\"\\n📄 Classification Report:\")\n",
    "        print(report)\n",
    "\n",
    "        # TensorBoard: log confusion matrix as image (optional)\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            import seaborn as sns\n",
    "\n",
    "            fig = plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "            plt.xlabel(\"Predicted\")\n",
    "            plt.ylabel(\"True\")\n",
    "            plt.title(\"Confusion Matrix\")\n",
    "            writer.add_figure(\"Confusion Matrix\", fig, epoch)\n",
    "            plt.close(fig)\n",
    "        except ImportError:\n",
    "            pass  # If matplotlib/seaborn not installed, skip plotting\n",
    "\n",
    "    # === Early Stopping ===\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        early_stop_counter = 0\n",
    "        print(\"🔖 Best model updated.\")\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        print(f\"⚠️ No improvement in validation loss for {early_stop_counter} epoch(s).\")\n",
    "\n",
    "    if early_stop_counter >= patience:\n",
    "        print(\"⛔ Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "# Load best weights\n",
    "model.load_state_dict(best_model_wts)\n",
    "\n",
    "# Save best model\n",
    "# torch.save(model.state_dict(), \"best_timesformer_model.pth\")\n",
    "print(\"✅ Best model saved to 'best_timesformer_model.pth'\")\n",
    "\n",
    "# Close TensorBoard writer\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # r\"F:\\quest_digiflex\\exp\\data\\archive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 [Train]: 100%|████████████████████████████████████████████████████████████| 118/118 [19:17<00:00,  9.81s/it]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 30/30 [02:56<00:00,  5.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=2.9983, Val Acc=0.1695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 [Train]: 100%|████████████████████████████████████████████████████████████| 118/118 [15:37<00:00,  7.94s/it]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 30/30 [02:45<00:00,  5.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=2.9370, Val Acc=0.1949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 [Train]: 100%|████████████████████████████████████████████████████████████| 118/118 [15:48<00:00,  8.04s/it]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 30/30 [02:42<00:00,  5.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=2.8825, Val Acc=0.1864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 [Train]: 100%|████████████████████████████████████████████████████████████| 118/118 [17:31<00:00,  8.91s/it]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 30/30 [02:58<00:00,  5.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=2.8790, Val Acc=0.1695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 [Train]: 100%|████████████████████████████████████████████████████████████| 118/118 [15:43<00:00,  7.99s/it]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 30/30 [02:20<00:00,  4.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=2.8682, Val Acc=0.1949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 [Train]: 100%|████████████████████████████████████████████████████████████| 118/118 [18:05<00:00,  9.20s/it]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 30/30 [03:03<00:00,  6.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=2.8201, Val Acc=0.1695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 [Train]: 100%|████████████████████████████████████████████████████████████| 118/118 [16:02<00:00,  8.16s/it]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 30/30 [02:38<00:00,  5.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=2.8266, Val Acc=0.2119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 [Train]: 100%|████████████████████████████████████████████████████████████| 118/118 [15:13<00:00,  7.74s/it]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 30/30 [02:22<00:00,  4.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=2.8027, Val Acc=0.1441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 [Train]: 100%|████████████████████████████████████████████████████████████| 118/118 [14:34<00:00,  7.41s/it]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 30/30 [02:40<00:00,  5.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss=2.7887, Val Acc=0.1610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 [Train]: 100%|███████████████████████████████████████████████████████████| 118/118 [16:34<00:00,  8.42s/it]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 30/30 [02:44<00:00,  5.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss=2.7538, Val Acc=0.2119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 [Train]: 100%|███████████████████████████████████████████████████████████| 118/118 [16:15<00:00,  8.27s/it]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 30/30 [02:46<00:00,  5.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=2.7396, Val Acc=0.2119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 [Train]: 100%|███████████████████████████████████████████████████████████| 118/118 [16:12<00:00,  8.24s/it]\n",
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 30/30 [02:53<00:00,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=2.6601, Val Acc=0.1949\n",
      "Early stopping triggered.\n",
      "Training complete. Best Val Acc: 0.211864406779661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -------------------------------\n",
    "# Configuration\n",
    "# -------------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "VIDEO_DIR =  r\"F:\\quest_digiflex\\exp\\data\\archive\"\n",
    "NUM_FRAMES = 16\n",
    "IMAGE_SIZE = 112\n",
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 30\n",
    "PATIENCE = 5\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -------------------------------\n",
    "# Utils\n",
    "# -------------------------------\n",
    "def read_video(path, num_frames):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    if total_frames < num_frames:\n",
    "        return None  # skip too-short videos\n",
    "\n",
    "    indices = np.linspace(0, total_frames - 1, num_frames).astype(int)\n",
    "    i = 0\n",
    "    count = 0\n",
    "    while cap.isOpened() and count < num_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if i in indices:\n",
    "            frame = cv2.resize(frame, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "            count += 1\n",
    "        i += 1\n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "# -------------------------------\n",
    "# Dataset\n",
    "# -------------------------------\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, num_frames=16, augment=True):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.num_frames = num_frames\n",
    "        self.augment = augment\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.RandomHorizontalFlip(p=0.5) if augment else transforms.Lambda(lambda x: x),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        frames = read_video(video_path, self.num_frames)\n",
    "\n",
    "        if frames is None:\n",
    "            return self.__getitem__((idx + 1) % len(self.file_paths))  # try next\n",
    "\n",
    "        frames = [self.transform(frame) for frame in frames]\n",
    "        video_tensor = torch.stack(frames).permute(1, 0, 2, 3)  # (C, T, H, W)\n",
    "        return video_tensor, label\n",
    "\n",
    "# -------------------------------\n",
    "# Model\n",
    "# -------------------------------\n",
    "class Simple3DCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Simple3DCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv3d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2),\n",
    "\n",
    "            nn.Conv3d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2),\n",
    "\n",
    "            nn.Conv3d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.features(x))\n",
    "\n",
    "# -------------------------------\n",
    "# Data Preparation\n",
    "# -------------------------------\n",
    "def load_data():\n",
    "    class_to_idx = {cls: idx for idx, cls in enumerate(os.listdir(VIDEO_DIR))}\n",
    "    file_paths = []\n",
    "    labels = []\n",
    "    for cls in class_to_idx:\n",
    "        folder = os.path.join(VIDEO_DIR, cls)\n",
    "        for file in os.listdir(folder):\n",
    "            if file.endswith(\".mp4\"):\n",
    "                file_paths.append(os.path.join(folder, file))\n",
    "                labels.append(class_to_idx[cls])\n",
    "    return file_paths, labels, len(class_to_idx)\n",
    "\n",
    "file_paths, labels, num_classes = load_data()\n",
    "train_files, val_files, train_labels, val_labels = train_test_split(\n",
    "    file_paths, labels, test_size=0.2, random_state=SEED, stratify=labels\n",
    ")\n",
    "\n",
    "train_dataset = VideoDataset(train_files, train_labels, NUM_FRAMES, augment=True)\n",
    "val_dataset = VideoDataset(val_files, val_labels, NUM_FRAMES, augment=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# -------------------------------\n",
    "# Training\n",
    "# -------------------------------\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience):\n",
    "    best_acc = 0.0\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(val_loader, desc=\"Validating\"):\n",
    "                inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += (preds == targets).sum().item()\n",
    "                total += targets.size(0)\n",
    "\n",
    "        val_acc = val_correct / total\n",
    "        print(f\"Epoch {epoch+1}: Train Loss={running_loss/len(train_loader):.4f}, Val Acc={val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"best_model.pt\")\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    print(\"Training complete. Best Val Acc:\", best_acc)\n",
    "\n",
    "# -------------------------------\n",
    "# Run Everything\n",
    "# -------------------------------\n",
    "model = Simple3DCNN(num_classes).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, NUM_EPOCHS, PATIENCE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Custom save path (Windows-style path with escaped backslashes or raw string)\n",
    "custom_path = r\"F:\\quest_digiflex\\exp\\devanshi\\model\\best_model.pth\"\n",
    "\n",
    "# Ensure directory exists\n",
    "os.makedirs(os.path.dirname(custom_path), exist_ok=True)\n",
    "\n",
    "# # Inside your training loop, after validation:\n",
    "# if val_loss < best_val_loss:\n",
    "#     best_val_loss = val_loss\n",
    "torch.save(model.state_dict(), custom_path)\n",
    "print(f\"🔖 Best model saved at: {custom_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I_7yU4wFl33a"
   },
   "outputs": [],
   "source": [
    "# Save the full model (recommended for ease)\n",
    "torch.save(model, \"timesformer_exercise_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0x1oIOpy7NLz"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the full model object (must be in the same session when loading)\n",
    "with open(\"timesformer_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GIKa_3Xb7Vz7",
    "outputId": "b1a71cf0-1180-47ff-8698-17c15b4867db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimesformerForVideoClassification(\n",
       "  (timesformer): TimesformerModel(\n",
       "    (embeddings): TimesformerEmbeddings(\n",
       "      (patch_embeddings): TimesformerPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "      (time_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): TimesformerEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x TimesformerLayer(\n",
       "          (drop_path): Identity()\n",
       "          (attention): TimeSformerAttention(\n",
       "            (attention): TimesformerSelfAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): TimesformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): TimesformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): TimesformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (temporal_attention): TimeSformerAttention(\n",
       "            (attention): TimesformerSelfAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): TimesformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=22, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"timesformer_model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "akOHr-Ap7YHG"
   },
   "outputs": [],
   "source": [
    "def predict(video_tensor):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = video_tensor.unsqueeze(0).to(device)\n",
    "        outputs = model(inputs)\n",
    "        predicted_class = outputs.logits.argmax(dim=1).item()\n",
    "        return predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIpI3Lar7dyR"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load model (if not already loaded)\n",
    "# model = torch.load(\"timesformer_exercise_model.pth\")\n",
    "# model.to(device)\n",
    "\n",
    "# Reverse label map\n",
    "idx_to_label = {v: k for k, v in dataset.label_map.items()}\n",
    "\n",
    "video_path = \"sample_video.mp4\"\n",
    "predicted_class = predict_from_video_path(video_path, model, device, idx_to_label)\n",
    "print(f\"Predicted class: {predicted_class}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0258a7d497f840f09c50beebb929b991": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b00972f4ff314f58bae95d24a052f3c3",
      "placeholder": "​",
      "style": "IPY_MODEL_1a7eca0d2895457fbb9bddaf906af02a",
      "value": " 22.7k/22.7k [00:00&lt;00:00, 1.20MB/s]"
     }
    },
    "03337622938e48aa8090a1d7b217094b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d2fe3ecdce547cdbd6f589267d3f60e",
      "placeholder": "​",
      "style": "IPY_MODEL_cf37ac8ef8e748cf813e3c2bc1941342",
      "value": " 486M/486M [00:05&lt;00:00, 142MB/s]"
     }
    },
    "0341a5867eb742849873a4b6dfc193ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0ae7c7022b3a4846b968bed5bd3ad002": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e560b288566343bfb751b00c49df5245",
       "IPY_MODEL_35d19eecca2343c8a3af41706f8f15ae",
       "IPY_MODEL_03337622938e48aa8090a1d7b217094b"
      ],
      "layout": "IPY_MODEL_ff7d006720c64044b24213c17fdaea0d"
     }
    },
    "13fa456b32ea4c2abde46707d3411759": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a7eca0d2895457fbb9bddaf906af02a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1c334228a6e04e6984b0e02e4671c0bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d46f57a4139642ba81dbaf164c79def5",
       "IPY_MODEL_912e2a48a51a4737bcabf960a187e559",
       "IPY_MODEL_3fef5db636504f748b9f05bd8c64b6b8"
      ],
      "layout": "IPY_MODEL_31e14adcb3584941a764e8629929a20c"
     }
    },
    "24b9f1f7e7bd4898a355eedc83b55f30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d2fe3ecdce547cdbd6f589267d3f60e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31187a84c89d48a09ba0b71def1fb1d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31e14adcb3584941a764e8629929a20c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35d19eecca2343c8a3af41706f8f15ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13fa456b32ea4c2abde46707d3411759",
      "max": 486348721,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5b9056559af0492abb2aeca2ecf0b9ed",
      "value": 486348721
     }
    },
    "3fef5db636504f748b9f05bd8c64b6b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c5baf33f1284414ad277433712e501f",
      "placeholder": "​",
      "style": "IPY_MODEL_60961e2f069e401f9e4b0284e4e64c22",
      "value": " 412/412 [00:00&lt;00:00, 36.5kB/s]"
     }
    },
    "43bb44e0846b4e57973cb90b75885e74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "57c07df903ba4ad3b6ffa7e4130406a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_79f594f490fd479b90717cfbf5d0d5c3",
       "IPY_MODEL_b6192186e7ee4927bda7789eb2bb4c10",
       "IPY_MODEL_0258a7d497f840f09c50beebb929b991"
      ],
      "layout": "IPY_MODEL_ead8aea3dda94bc7bf96f5025d30850f"
     }
    },
    "5b9056559af0492abb2aeca2ecf0b9ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "60961e2f069e401f9e4b0284e4e64c22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c5baf33f1284414ad277433712e501f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "749bd61c8a994cba9c26cebfc176f976": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79f594f490fd479b90717cfbf5d0d5c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec19fd1b8b6c4ef08037af48d2129dbf",
      "placeholder": "​",
      "style": "IPY_MODEL_749bd61c8a994cba9c26cebfc176f976",
      "value": "config.json: 100%"
     }
    },
    "87b51556dcd2484c9b722744e99156e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "912e2a48a51a4737bcabf960a187e559": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87b51556dcd2484c9b722744e99156e8",
      "max": 412,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c55a0520f6db4374b1a84266f0bbd23c",
      "value": 412
     }
    },
    "a9180d1612a64b639089127534cdaf9d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b00972f4ff314f58bae95d24a052f3c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6192186e7ee4927bda7789eb2bb4c10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24b9f1f7e7bd4898a355eedc83b55f30",
      "max": 22723,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_43bb44e0846b4e57973cb90b75885e74",
      "value": 22723
     }
    },
    "bff9f3a9198a45b5ba83f1296123a0d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c55a0520f6db4374b1a84266f0bbd23c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cf37ac8ef8e748cf813e3c2bc1941342": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d46f57a4139642ba81dbaf164c79def5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_31187a84c89d48a09ba0b71def1fb1d7",
      "placeholder": "​",
      "style": "IPY_MODEL_0341a5867eb742849873a4b6dfc193ed",
      "value": "preprocessor_config.json: 100%"
     }
    },
    "e560b288566343bfb751b00c49df5245": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a9180d1612a64b639089127534cdaf9d",
      "placeholder": "​",
      "style": "IPY_MODEL_bff9f3a9198a45b5ba83f1296123a0d6",
      "value": "pytorch_model.bin: 100%"
     }
    },
    "ead8aea3dda94bc7bf96f5025d30850f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec19fd1b8b6c4ef08037af48d2129dbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff7d006720c64044b24213c17fdaea0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
